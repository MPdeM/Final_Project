{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidl_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3RVZXRhzPMJ"
      },
      "source": [
        "## **Install Pytorch/ Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFKC60hGzMsb",
        "outputId": "4cda3993-6f0b-49b2-eee0-ec419dcf8a92"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/6d/1c43d87bfff9e7afb5130629dfb7d57617245eeb4a474bf77f45d637c3a6/boto3-1.17.33-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.0+cu101)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Collecting botocore<1.21.0,>=1.20.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/1c/f922d7fa47cdd6a18c7470252e86f7c4d24e85cb3cdff09486675df3769c/botocore-1.20.33-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 7.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.33->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.33->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.33 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.33 botocore-1.20.33 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38zusI_yzMsf"
      },
      "source": [
        "# Dependencies\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "import torch.nn as nn\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZTFzJvvzaCt"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "KhxVIR6mzMsi",
        "outputId": "4730dcbc-c13f-4e9b-e92b-3976551c8c4d"
      },
      "source": [
        "# Read in csv file\n",
        "# url = \"https://job-postings-dataviz.s3.amazonaws.com/fake_job_postings.csv\"\n",
        "path = \"/content/fake_job_postings.csv\" # if read from Drive\n",
        "\n",
        "df = pd.read_csv(path, encoding = \"UTF-8\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "      <th>fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Marketing Intern</td>\n",
              "      <td>US, NY, New York</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
              "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
              "      <td>Experience with content management systems a m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>Internship</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Customer Service - Cloud Video Production</td>\n",
              "      <td>NZ, , Auckland</td>\n",
              "      <td>Success</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
              "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
              "      <td>What we expect from you:Your key responsibilit...</td>\n",
              "      <td>What you will get from usThrough being part of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing and Advertising</td>\n",
              "      <td>Customer Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
              "      <td>US, IA, Wever</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Valor Services provides Workforce Solutions th...</td>\n",
              "      <td>Our client, located in Houston, is actively se...</td>\n",
              "      <td>Implement pre-commissioning and commissioning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Account Executive - Washington DC</td>\n",
              "      <td>US, DC, Washington</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our passion for improving quality of life thro...</td>\n",
              "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
              "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
              "      <td>Our culture is anything but corporate—we have ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Bill Review Manager</td>\n",
              "      <td>US, FL, Fort Worth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
              "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
              "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
              "      <td>Full Benefits Offered</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Hospital &amp; Health Care</td>\n",
              "      <td>Health Care Provider</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   job_id  ... fraudulent\n",
              "0       1  ...          0\n",
              "1       2  ...          0\n",
              "2       3  ...          0\n",
              "3       4  ...          0\n",
              "4       5  ...          0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "FYYhtv74DjTg",
        "outputId": "d8d1f6f7-71e6-4ed3-9cfb-00684285d2e7"
      },
      "source": [
        "# remove the NaN (they tend to mess up)\n",
        "df.fillna(\" \", inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "      <th>fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Marketing Intern</td>\n",
              "      <td>US, NY, New York</td>\n",
              "      <td>Marketing</td>\n",
              "      <td></td>\n",
              "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
              "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
              "      <td>Experience with content management systems a m...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>Internship</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Marketing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Customer Service - Cloud Video Production</td>\n",
              "      <td>NZ, , Auckland</td>\n",
              "      <td>Success</td>\n",
              "      <td></td>\n",
              "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
              "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
              "      <td>What we expect from you:Your key responsibilit...</td>\n",
              "      <td>What you will get from usThrough being part of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td></td>\n",
              "      <td>Marketing and Advertising</td>\n",
              "      <td>Customer Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
              "      <td>US, IA, Wever</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Valor Services provides Workforce Solutions th...</td>\n",
              "      <td>Our client, located in Houston, is actively se...</td>\n",
              "      <td>Implement pre-commissioning and commissioning ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Account Executive - Washington DC</td>\n",
              "      <td>US, DC, Washington</td>\n",
              "      <td>Sales</td>\n",
              "      <td></td>\n",
              "      <td>Our passion for improving quality of life thro...</td>\n",
              "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
              "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
              "      <td>Our culture is anything but corporate—we have ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Bill Review Manager</td>\n",
              "      <td>US, FL, Fort Worth</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
              "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
              "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
              "      <td>Full Benefits Offered</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Hospital &amp; Health Care</td>\n",
              "      <td>Health Care Provider</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   job_id  ... fraudulent\n",
              "0       1  ...          0\n",
              "1       2  ...          0\n",
              "2       3  ...          0\n",
              "3       4  ...          0\n",
              "4       5  ...          0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "OSsmgutMOHge",
        "outputId": "32a0e5b5-ce84-430e-a7a1-b79f488c01bc"
      },
      "source": [
        "# Check if there is any relationship between the target class and required_education\n",
        "df.pivot_table(index=['fraudulent'], columns='required_education', aggfunc='size', fill_value=0)\n",
        "# there is no relationship and can be removed"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>required_education</th>\n",
              "      <th></th>\n",
              "      <th>Associate Degree</th>\n",
              "      <th>Bachelor's Degree</th>\n",
              "      <th>Certification</th>\n",
              "      <th>Doctorate</th>\n",
              "      <th>High School or equivalent</th>\n",
              "      <th>Master's Degree</th>\n",
              "      <th>Professional</th>\n",
              "      <th>Some College Coursework Completed</th>\n",
              "      <th>Some High School Coursework</th>\n",
              "      <th>Unspecified</th>\n",
              "      <th>Vocational</th>\n",
              "      <th>Vocational - Degree</th>\n",
              "      <th>Vocational - HS Diploma</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7654</td>\n",
              "      <td>268</td>\n",
              "      <td>5045</td>\n",
              "      <td>151</td>\n",
              "      <td>25</td>\n",
              "      <td>1910</td>\n",
              "      <td>385</td>\n",
              "      <td>70</td>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>1336</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>451</td>\n",
              "      <td>6</td>\n",
              "      <td>100</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "required_education        ...  Vocational - HS Diploma\n",
              "fraudulent                ...                         \n",
              "0                   7654  ...                        9\n",
              "1                    451  ...                        0\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "gaS0aocvNPzV",
        "outputId": "164ecb95-8de1-4437-9ccf-59b29325f20c"
      },
      "source": [
        "# Check if there is any relationship between the target class and required_experience\n",
        "df.pivot_table(index=['fraudulent'], columns='required_experience', aggfunc='size', fill_value=0)\n",
        "# there is no relationship and can be removed"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>required_experience</th>\n",
              "      <th></th>\n",
              "      <th>Associate</th>\n",
              "      <th>Director</th>\n",
              "      <th>Entry level</th>\n",
              "      <th>Executive</th>\n",
              "      <th>Internship</th>\n",
              "      <th>Mid-Senior level</th>\n",
              "      <th>Not Applicable</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6615</td>\n",
              "      <td>2255</td>\n",
              "      <td>372</td>\n",
              "      <td>2518</td>\n",
              "      <td>131</td>\n",
              "      <td>371</td>\n",
              "      <td>3696</td>\n",
              "      <td>1056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>435</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "      <td>179</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>113</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "required_experience        Associate  ...  Mid-Senior level  Not Applicable\n",
              "fraudulent                            ...                                  \n",
              "0                    6615       2255  ...              3696            1056\n",
              "1                     435         42  ...               113              60\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "0WxmemfnNx17",
        "outputId": "a06824ef-2927-4e3d-aae3-0c26abda74a1"
      },
      "source": [
        "# Check if there is any relationship between the target class and employment_type\n",
        "df.pivot_table(index=['fraudulent'], columns='employment_type', aggfunc='size', fill_value=0)\n",
        "# there is no relationship and can be removed"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>employment_type</th>\n",
              "      <th></th>\n",
              "      <th>Contract</th>\n",
              "      <th>Full-time</th>\n",
              "      <th>Other</th>\n",
              "      <th>Part-time</th>\n",
              "      <th>Temporary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3230</td>\n",
              "      <td>1480</td>\n",
              "      <td>11130</td>\n",
              "      <td>212</td>\n",
              "      <td>723</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>241</td>\n",
              "      <td>44</td>\n",
              "      <td>490</td>\n",
              "      <td>15</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "employment_type        Contract  Full-time  Other  Part-time  Temporary\n",
              "fraudulent                                                             \n",
              "0                3230      1480      11130    212        723        239\n",
              "1                 241        44        490     15         74          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLR58R6KPIw1"
      },
      "source": [
        "# concatenate the data \n",
        "\n",
        "df['text'] = df['title']+ \" \" + df['department'] + \" \" + df['company_profile']+ \" \" + df['description']+ \" \" + df['requirements'] + \" \" + df['benefits'] + \" \"\n",
        " "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlQlJWyPV5gE",
        "outputId": "b2659ee9-44e9-4a04-b14b-181cc4c63d1f"
      },
      "source": [
        "df['text'] "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Marketing Intern Marketing We're Food52, and w...\n",
              "1        Customer Service - Cloud Video Production Succ...\n",
              "2        Commissioning Machinery Assistant (CMA)   Valo...\n",
              "3        Account Executive - Washington DC Sales Our pa...\n",
              "4        Bill Review Manager   SpotSource Solutions LLC...\n",
              "                               ...                        \n",
              "17875    Account Director - Distribution  Sales Vend is...\n",
              "17876    Payroll Accountant Accounting WebLinc is the e...\n",
              "17877    Project Cost Control Staff Engineer - Cost Con...\n",
              "17878    Graphic Designer     Nemsia Studios is looking...\n",
              "17879    Web Application Developers Engineering Vend is...\n",
              "Name: text, Length: 17880, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_5e3336DEy_",
        "outputId": "dc6570e7-dfd2-46f6-85f4-55aa6a078fe5"
      },
      "source": [
        "list(df.columns)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['job_id',\n",
              " 'title',\n",
              " 'location',\n",
              " 'department',\n",
              " 'salary_range',\n",
              " 'company_profile',\n",
              " 'description',\n",
              " 'requirements',\n",
              " 'benefits',\n",
              " 'telecommuting',\n",
              " 'has_company_logo',\n",
              " 'has_questions',\n",
              " 'employment_type',\n",
              " 'required_experience',\n",
              " 'required_education',\n",
              " 'industry',\n",
              " 'function',\n",
              " 'fraudulent',\n",
              " 'text']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9QkQvg9Sd5S"
      },
      "source": [
        "delete_list=['job_id',\n",
        " 'title',\n",
        " 'location',\n",
        " 'department',\n",
        " 'salary_range',\n",
        " 'company_profile',\n",
        " 'description',\n",
        " 'requirements',\n",
        " 'benefits',\n",
        " 'telecommuting',\n",
        " 'has_company_logo',\n",
        " 'has_questions',\n",
        " 'employment_type',\n",
        " 'required_experience',\n",
        " 'required_education',\n",
        " 'industry',\n",
        " 'function'\n",
        "]\n",
        "\n",
        "for column in delete_list:\n",
        "  del df[column]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "u7aIOnDTVw6D",
        "outputId": "cd457e3d-1bdd-4d45-b5a0-0361f8667d72"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraudulent</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Marketing Intern Marketing We're Food52, and w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Customer Service - Cloud Video Production Succ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)   Valo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Account Executive - Washington DC Sales Our pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Bill Review Manager   SpotSource Solutions LLC...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fraudulent                                               text\n",
              "0           0  Marketing Intern Marketing We're Food52, and w...\n",
              "1           0  Customer Service - Cloud Video Production Succ...\n",
              "2           0  Commissioning Machinery Assistant (CMA)   Valo...\n",
              "3           0  Account Executive - Washington DC Sales Our pa...\n",
              "4           0  Bill Review Manager   SpotSource Solutions LLC..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShPKXuz2fE1m"
      },
      "source": [
        "## **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP08keQUSt-o"
      },
      "source": [
        "df['text']=df['text'].str.replace('\\n','')\n",
        "df['text']=df['text'].str.replace('\\r','')\n",
        "df['text']=df['text'].str.replace('\\t','')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvTyQgTSuEc"
      },
      "source": [
        "# remove numbers and simbols\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'[0-9]','',x))\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDj3WO2WSuJt"
      },
      "source": [
        "# convert all to lowers\n",
        "\n",
        "df[\"text\"] = df['text'].apply(lambda s: s.lower() if type(s) == str else s)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZp27XEkSuOq"
      },
      "source": [
        "# remove unnecesary white spaces\n",
        "\n",
        "df['text'] = df['text'].str.replace('  ', ' ')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cAPFwUeDP8h"
      },
      "source": [
        "## **Bert Pretrained layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaUJy7wsMQ_g",
        "outputId": "dd6335bf-2856-4f69-ab7b-38f31d391fa1"
      },
      "source": [
        "# Using Google TensorFlow library for the Bert model \n",
        "\n",
        "# install tesorflow bert package\n",
        "!pip install bert-for-tf2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=cb1b335845a3d1f3791cd6de5418977beef797c4a1cd4254b5539be338150556\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=a231fa1b0d860a61a30baeb2096926868dd3cdb8f10ca2e9c6bea969812766cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=f47af2761529ac0df262be476468684037ebf11fc26c404e8710ee53e020b34f\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQcV4zUuD3Nd"
      },
      "source": [
        "#Loding pretrained bert layer\n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi8X702OD-eP"
      },
      "source": [
        "# Loading tokenizer from the bert layer\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBaFcElJD_CJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9osoEDPESvB"
      },
      "source": [
        "## Bert Encoding\n",
        "- each sentence is tolkenized into tolkens\n",
        "- a [CLS] token is added at the beginning of the first sentence and [SEP] token at the end\n",
        "- tokens that coply with fixed vocabulary are fetched and assigned with: \n",
        "  - token IDs, to assign Unique token-id from BERT's tokenizer\n",
        "  - padding ID (Mask-Id), to indicate which elements in the sequence are tokens and which are padding elements\n",
        "  - Segment IDs, to distinguish different sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ws3-z-ID_eQ",
        "outputId": "c08e8c0b-d398-4b65-f1cb-8f74874cee89"
      },
      "source": [
        "text = \" All I need is within me now\"\n",
        "# tokenize\n",
        "tokens_list = tokenizer.tokenize(text)\n",
        "print('Text after tokenization')\n",
        "print(tokens_list)\n",
        "# initilize dimension\n",
        "max_len =25\n",
        "text = tokens_list[:max_len-2]\n",
        "input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "print(\"After adding  flasges -[CLS] and [SEP]: \")\n",
        "print(input_sequence)\n",
        "\n",
        "tokens = tokenizer.convert_tokens_to_ids(input_sequence )\n",
        "print(\"tokens to id \")\n",
        "print(tokens)\n",
        "\n",
        "pad_len = max_len -len(input_sequence)\n",
        "tokens += [0] * pad_len\n",
        "print(\"tokens: \")\n",
        "print(tokens)\n",
        "\n",
        "pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "print(\"Pad Masking: \")\n",
        "print(pad_masks)\n",
        "\n",
        "segment_ids = [0] * max_len\n",
        "print(\"Segment Ids: \")\n",
        "print(segment_ids)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text after tokenization\n",
            "['all', 'i', 'need', 'is', 'within', 'me', 'now']\n",
            "After adding  flasges -[CLS] and [SEP]: \n",
            "['[CLS]', 'all', 'i', 'need', 'is', 'within', 'me', 'now', '[SEP]']\n",
            "tokens to id \n",
            "[101, 2035, 1045, 2342, 2003, 2306, 2033, 2085, 102]\n",
            "tokens: \n",
            "[101, 2035, 1045, 2342, 2003, 2306, 2033, 2085, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Pad Masking: \n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segment Ids: \n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MpN3oGNzMst",
        "outputId": "579d80c6-5b6c-465a-aacf-67d10f4c0680"
      },
      "source": [
        "# Make sure number of real vs fraudulent are more balanced\n",
        "# Using UNDERsampling for balancing of classification groups\n",
        "df_fake = df[df['fraudulent'] == 1] \n",
        "df_real = df[df['fraudulent'] == 0] \n",
        "\n",
        "n_f=len(df_fake)\n",
        "n_n=len(df_real)\n",
        "print(n_f)\n",
        "print(n_n)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "866\n",
            "17014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKO8VCLJNeID",
        "outputId": "a98c6f8d-f564-4caa-faf3-76abcea9011e"
      },
      "source": [
        "# Create a dataset with a more balanced distribution df_under(5:1 real:fake posts)\n",
        "df_new= df_real.sample( 5*len(df_fake), random_state=580)\n",
        "df_unders = df_new.append(df_fake)\n",
        "print(len(df_new))\n",
        "print(len(df_unders))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4330\n",
            "5196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0Tj8F-gtM9A1",
        "outputId": "c305bd83-1a80-412e-e7ac-b132642b16c6"
      },
      "source": [
        "# Shuffle the dataframe \n",
        "# from sklearn.utils import shuffle\n",
        "# df_underst = shuffle(df_unders, random_state=22)\n",
        "df_underst = df_unders.sample(len(df_unders), random_state=580) \n",
        "df = df_underst.reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraudulent</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>vp product strategy &amp; analysis credit strategy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>digital analytics and strategy manager  freque...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tech support specialist support hirehopes is t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>technical support engineer operations upstream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>senior network engineer engineering upstream’s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fraudulent                                               text\n",
              "0           0  vp product strategy & analysis credit strategy...\n",
              "1           0  digital analytics and strategy manager  freque...\n",
              "2           0  tech support specialist support hirehopes is t...\n",
              "3           0  technical support engineer operations upstream...\n",
              "4           0  senior network engineer engineering upstream’s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYldfyZ4bE7X",
        "outputId": "6297c81a-9a1f-4e9f-d375-7580e316d90e"
      },
      "source": [
        "X = df['text']        #Tokenize the dataset\n",
        "Y = df['fraudulent']   #Assign the value of y  \n",
        "print(Y.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5196,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIHJoU5XbL6O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,Y , test_size = 0.20,random_state=41)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te4xxeRQVCt-"
      },
      "source": [
        "Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHhxkE9wftLr"
      },
      "source": [
        "\n",
        "\n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "# encode train set \n",
        "train_input = bert_encode(X_train, tokenizer, max_len=MAX_LEN)\n",
        "# encode  test set \n",
        "test_input = bert_encode(X_test, tokenizer, max_len= MAX_LEN )\n",
        "train_labels = y_train    "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOYPnLqtcNo-",
        "outputId": "eb24019e-be4b-4c09-9e0f-2c631953742d"
      },
      "source": [
        "# lets see encoded train set \n",
        "train_input"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  101,  2406,  3208, ...,  5198, 10095,   102],\n",
              "        [  101,  2451,  1004, ...,  9273,  2040,   102],\n",
              "        [  101,  3026,  8290, ...,  3265,  2007,   102],\n",
              "        ...,\n",
              "        [  101,  4748, 10020, ...,  2154,  2000,   102],\n",
              "        [  101,  2393,  4624, ..., 24529,  2099,   102],\n",
              "        [  101,  3208,  8013, ...,  1037, 13024,   102]]),\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFagGgrQftQZ"
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IyUtQM5ftVB"
      },
      "source": [
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a2P49sCgW8v0",
        "outputId": "e5fb3470-1df5-4081-a43e-3810131211bc"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraudulent</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>marketing intern marketing we're food and we'v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>customer service cloud video production succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>commissioning machinery assistant cma valor se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>account executive washington dc sales our pass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>bill review manager spotsource solutions llc i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fraudulent                                               text\n",
              "0           0  marketing intern marketing we're food and we'v...\n",
              "1           0  customer service cloud video production succes...\n",
              "2           0  commissioning machinery assistant cma valor se...\n",
              "3           0  account executive washington dc sales our pass...\n",
              "4           0  bill review manager spotsource solutions llc i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1QPoa0xYRA8",
        "outputId": "cc7f95e2-709e-44d8-d570-855f93a8bd4d"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17880,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBaZ3ADKYRKo",
        "outputId": "b250e41d-72b5-40b3-a4b8-77a3b64fa82e"
      },
      "source": [
        "model = build_model(bert_layer, max_len=160)\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer_2[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf.__operators__.getitem[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3sbubUKeFha"
      },
      "source": [
        "## Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "lGfpSG8wZNVH",
        "outputId": "39600560-fbb7-4e70-cbd3-725d95163d7a"
      },
      "source": [
        "\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=3,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-a41e83f46dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 160), found shape=(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bTA8vMoOZ49x",
        "outputId": "7fc9ec9e-8785-4fd9-ea50-628e05cff456"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d2b50fb5a1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/tokenization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msentencepiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mSPIECE_UNDERLINE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"▁\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentencepiece'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "J_1qwNDzYRUE",
        "outputId": "3712d5da-4a22-46c7-e571-18b7de26e17d"
      },
      "source": [
        "from bert import bert_tokenization\n",
        "BertTokenizer = bert_tokenization.FullTokenizer\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-03a409d219e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tokenization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msentencepiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mSPIECE_UNDERLINE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"▁\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentencepiece'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIUib2Oa3Eb9",
        "outputId": "7465e4f9-0e0f-47b8-c296-7c63cc64ede5"
      },
      "source": [
        "\n",
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "YYZJeWdSYRcp",
        "outputId": "a7f3153f-4f98-40f0-c2e4-82a57f25b1b1"
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "# BERT imports\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.17.33)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.33 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.20.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.33->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.33->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fvxx-qQYRl9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZC6dr9YRzO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAqEfo08YR9X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI7mSkbszeQL"
      },
      "source": [
        "## **Training/Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkbI2fTWzMs4",
        "outputId": "5370de55-6998-4ae0-9018-9c7bffc2fb33"
      },
      "source": [
        "# Split the data into training and testing\n",
        "train_data = df.head(885)\n",
        "test_data = df.tail(885)\n",
        "\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(885, 2) (885, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezduM9eszMs6"
      },
      "source": [
        "# Generate a list of dictionaries with ‘description’ and ‘fraudulent’ keys\n",
        "# Guidance provided by https://towardsdatascience.com/fake-job-classification-with-bert-6575c908a9aa\n",
        "train_data = [{'description': description, 'fraudulent': fraudulent } for description in list(train_data['description']) for fraudulent in list(train_data['fraudulent'])]\n",
        "\n",
        "test_data = [{'description': description, 'fraudulent': fraudulent } for description in list(test_data['description'])for fraudulent in list(test_data['fraudulent'])]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0JoSe-yzMs8"
      },
      "source": [
        "# Generate a list of tuples from the list of dictionaries\n",
        "train_texts, train_labels = list(zip(*map(lambda d: (d['description'], d['fraudulent']), train_data)))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtMIfzNOowTk"
      },
      "source": [
        "test_texts, test_labels = list(zip(*map(lambda d: (d['description'], d['fraudulent']), test_data)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NnxtqIuzmuE"
      },
      "source": [
        "## ** Bert pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcyOcXXoZxUp"
      },
      "source": [
        "\n",
        "Reference: https://www.kaggle.com/ratan123/in-depth-guide-to-google-s-bert/notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f83vKb8zMs_"
      },
      "source": [
        "# Generate tokens and token ids\n",
        "# Bert Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLAWiOuIzMtB"
      },
      "source": [
        "# Tokens\n",
        "#train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:128], train_texts))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k5tZWCYpIcX"
      },
      "source": [
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:128], test_texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn-g2yPLzMtD"
      },
      "source": [
        "# Token Ids\n",
        "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
        "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6l2cktXzMtG"
      },
      "source": [
        "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIimxMMwzMtH"
      },
      "source": [
        "# Generate a boolean array based on the value of ‘fraudulent’ for our testing and training sets\n",
        "train_y = np.array(train_labels) == 1\n",
        "test_y = np.array(test_labels) == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7jhnzKxzuYr"
      },
      "source": [
        "## **Building the BERT Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmvJGLRRzMtJ"
      },
      "source": [
        "# Create BERT classifier - contains ‘initialization’ method and ‘forward’ method; returns token probabilities\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK5K3wZhzMtK"
      },
      "source": [
        "# Generate training and testing masks\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j-4NzcwzMtM"
      },
      "source": [
        "# Generate token tensors for training and testing\n",
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppAEGegvzMtO"
      },
      "source": [
        "# Prepare data loaders\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
        "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHt7eUEaz3iX"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAVrUpkVzMtQ"
      },
      "source": [
        "# Use the Adam optimizer to minimize the Binary Cross Entropy loss \n",
        "# Train with a batch size of 1 for 1 EPOCHS\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "\n",
        "bert_clf = BertBinaryClassifier()\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        batch_loss = loss_func(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF2Ck_6Rz77E"
      },
      "source": [
        "## **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yu45dQKzMtU"
      },
      "source": [
        "# Evaluate our model\n",
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "        \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])\n",
        "        \n",
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}